{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sphères de Livermore\n",
    "\n",
    "\n",
    "## Description rapide de l'expérience\n",
    "\n",
    "Les expériences dites \"Sphères de Livermore\" ont été réalisées fin des années 60 - début des années 70 au Lawrence Livermore Laboratory (États-Unis).\n",
    "\n",
    "Une sphère creuse est placée au centre d'un bunker. En son centre on a une source de neutrons à 14 MeV (faisceau de $^2\\mathrm{H}^+$ sur une cible d'tritium, réaction $^3\\mathrm{H}(d, n)^4\\mathrm{He}$). Des détecteurs sont positionnés autour de la sphère après collimation.\n",
    "\n",
    "On observe le spectre en temps des neutrons qui arrivent dans les détecteurs (réponse type `REACTION` dans Tripoli-4).\n",
    "\n",
    "Pour une sphère donnée on exécute deux fois la simulation :\n",
    "- avec la sphère étudiée (matériau = fer, béryllium, azote, eau, etc)\n",
    "- avec la même sphère dont le matériau étudié a été remplacé par de l'**air**\n",
    "\n",
    "Cette seconde sphère nous permet de normaliser les résultats et de pouvoir nous comparer aux données expérimentales notamment grâce à un graphique. Il y a donc deux sorties Tripoli-4 à lire et des opérations à faire sur les spectres.\n",
    "\n",
    "Dans le cas présent la sphère considérée est celle d'azote liquide, d'une épaisseur de 3.1 mfp (libre parcours moyen), avec un spectre à 30°.\n",
    "\n",
    "<img src=\"N_3.1mfp.png\" width=\"600\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing des résultats Tripoli-4 et récupération du spectre\n",
    "\n",
    "### Parser les résultats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from valjean.eponine.tripoli4.parse import Parser\n",
    "jdd_sphere = 'prob103_nitrogen3.1_fine_timeShifted_sphere_PARA.d.res'\n",
    "jdd_air = 'prob103_nitrogen3.1_fine_timeShifted_air_PARA.d.res'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le module permettant de lire, parser et récupérer les résultats de Tripoli-4 sous un format plus facilement exploitable est `Parser`.\n",
    "\n",
    "On ne regardera ici que le résultat du dernier batch. Le parsing est effectivement fait par la méthode `parse_from_index`. L'index par défaut est `-1`, ce qui correspond au dernier batch.\n",
    "\n",
    "Pour manipuler plus aisément les réponses de Tripoli-4 et en particulier les sélectionner on utilise un objet `Browser`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sphere_b = Parser(jdd_sphere).parse_from_index(name='sphere').to_browser()\n",
    "air_b = Parser(jdd_air).parse_from_index(name='air').to_browser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sélection du résultat\n",
    "\n",
    "À chaque réponse dans ce jeu de données a été associé un `SCORE NAME` unique (et explicite). C'est le moyen le plus aisé de récupérer les réponses nécessaires.\n",
    "\n",
    "Dans le cas de la sphère (ici d'azote liquide), on récupère `score_name='neutron_response_30deg'`, soit le spectre neutron à 30 degrés (des spectres photons sont aussi disponibles). Il s'agira du numérateur (variable `nsphere`). Dans le cas de l'air, seule l'intégrale du spectre est nécessaire pour la normalisation, donc au dénominateur (variable `dair`). La sélection de la réponse se fait sur `score_name='neutron_response_integral_30deg'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsphere = sphere_b.select_by(score_name='neutron_response_30deg')\n",
    "dair = air_b.select_by(score_name='neutron_response_integral_30deg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation des données en `Dataset`\n",
    "\n",
    "Pour pouvoir manipuler les données plus aisément mais aussi pour faciliter leur manipulation, elles sont transformées en `Dataset`.\n",
    "\n",
    "Le but de `Dataset` est d'être commun à tous les types de données (Tripoli-4, données expérimentales, PATMOS, MCNP, etc). Chaque dataset contient au moins 2 membres : `value` et `error`. Il s'agit de l'incertitude absolue (et non pas relative comme dans les résultats standard Tripoli-4). Trois autres membres sont optionnels : `bins`, `name` et `what`.\n",
    "\n",
    "Les données sont stockées sous forme de `Dataset` accessible dans le `Browser` sous la clef `'results'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour info :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = nsphere['results']['score']\n",
    "print(type(test_ds))\n",
    "print(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_ds.squeeze().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour les manipuler plus simplement, les `Dataset` sont *squeezés* : nous récupérons des spectres en temps, les 6 autres dimensions sont donc à 1 et non utiles ici (et triviales)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsphereds = nsphere['results']['score'].squeeze()\n",
    "nsphereds.name=\"azote (num)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dairds = dair['results']['score'].squeeze()\n",
    "dairds.name='air (denom)'\n",
    "print(dairds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisation du spectre\n",
    "\n",
    "Le résultat correspondant à l'intégrale du spectre n'est en réalité ici pas un score générique, mais un réel spectre. Cette différence est due aux intervalles extrêmes :\n",
    "- entre t=0 et le début des résultats expérientaux, à t=138 ns pour le premier\n",
    "- entre t=410 ns et t=10 s pour le dernier, soit entre la fin des résultats expérimentaux et la valeur maximale du temps dans Tripoli-4\n",
    "\n",
    "Pour être plus juste, notamment au niveau du calcul des incertitudes associées, le choix a été fait de faire un spectre de 3 intervalles où seul celui du milieu nous intéresse dans le cas présent.\n",
    "\n",
    "L'incertitude sur la norme est négligée par la suite (elle est dominée par celle sur chaque intervalle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "norm = dairds.value[1]\n",
    "print(\"type(norm) = {0}, shape(norm) = {1}\".format(type(norm), norm.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En réalité deux normalisations du spectre sont à effectuer, celle par l'intégrale de l'air et celle par la largeur des bins, appelée ici `TIME_BIN_WIDTH`, valant 2&nbsp;ns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_BIN_WIDTH = 2\n",
    "t4ds = nsphereds / norm / TIME_BIN_WIDTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarque : il n'aurait pas été possible d'utiliser un `Dataset` issu de `dairds` pour la normalisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dairds)\n",
    "test_dairds = dairds.copy()[1:-1]\n",
    "print(test_dairds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "test_ds = nsphereds / test_dairds / TIME_BIN_WIDTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces deux datasets n'ont bien pas les shapes or les calculs sur les `Dataset` ne peuvent être effectués que s'ils ont la même *shape* et, dans le cas où des bins ont été fournis, si leurs bins sont équivalents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'shape(t4ds) = {0}, shape(test_dairds) = {1}'.format(t4ds.shape, test_dairds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réarrangement des intervalles\n",
    "\n",
    "Les temps sont par défaut en *s* dans Tripoli-4 alors que les données que nous avons à disposition sont données par intervalles de temps en *ns*, on convertit donc les intervalles de Tripoli-4 en *ns*.\n",
    "\n",
    "Par ailleurs, les intervalles en temps dans le jeu de données ont été décalés de 100 ns pour que la description de la source (gaussienne) soit correcte et complètement prise en compte dans le temps de la simulation (jeu de données tourné avec Tripoli-4, version 10.2, ce bug a été corrigé pour la version 11, mais c'est une jolie illustration des calculs possibles sur les `Dataset`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Bins en s et avant décalage:\\n',t4ds.bins['t'] )\n",
    "t4ds.bins['t'] = t4ds.bins['t'] * 1e9 - 100\n",
    "print('Bins en ns et après décalage:\\n', t4ds.bins['t'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De plus, le dataset actuel, `t4ds`, contient toujours les bins extrêmes, il faut donc les enlever.\n",
    "\n",
    "Le *slicing* a été codé dans `Dataset` : il est effectué en même temps sur les valeurs, sur les erreurs et sur les intervalles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('bins en temps (avant slicing):')\n",
    "print(t4ds.bins['t'])\n",
    "print(\"shape(t4ds) = {0}, bins(nom = {1}, shape = {2})\"\n",
    "      .format(t4ds.shape, list(t4ds.bins.keys()), t4ds.bins['t'].shape))\n",
    "t4ds = t4ds[1:-1]\n",
    "print('bins en temps (après slicing):')\n",
    "print(t4ds.bins['t'])\n",
    "print(\"shape(t4ds) = {0}, bins(nom = {1}, shape = {2})\"\n",
    "      .format(t4ds.shape, list(t4ds.bins.keys()), t4ds.bins['t'].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, les données issues de la simulation sont données par intervalle (avec les extémités des intervalles) alors que les données expérimentales sont données au centre de l'intervalle. Ces dernières sont également des `int` et non des `float` comme les temps issus de Tripoli-4. L'étape finale est donc de supprimer la première (ou dernière) valeur dans les *bins* et de toutes les décaler d'1 ns (largeur d'intervalle toujours de 2 ns) et de les transformer en `int`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t4ds.bins['t'] = np.rint(t4ds.bins['t'][1:] - 1)\n",
    "print(t4ds.bins['t'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le `Dataset` est maintenant prêt pour la comparaison aux données. On met simplement à jour son nom et la variable qu'il représente (ordonnée) pour le représenter explicitement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t4ds.name = 'T4'\n",
    "t4ds.what = 'Neutron count rate'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Résultats expérimentaux\n",
    "\n",
    "Les résultats expérimentaux sont fournis dans un fichier ASCII, sous forme de tableaux de valeurs. Il faut donc les parser et les transformer en `Dataset`.\n",
    "\n",
    "Cette étape est actuellement faite dans une petite classe externe : [LivermoreExps](livermore_exps.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livermore_exps import LivermoreExps\n",
    "\n",
    "exps = LivermoreExps('s10a11.res.mesure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toutes les données expérimentales sont ainsi disponibles, il suffit de les charger une seule fois pour toutes les analyses des sphères de Livermore. Ici on ne considèrera qu'un seul cas : `('NITROGEN', '3.1', '30')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_key = ('NITROGEN', '3.1', '30')\n",
    "exp_data = exps.res[exp_key]\n",
    "type(exp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(exp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les objets dans le dictionnaire de résultat (`exps.res`) sont des `Dataset`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison entre données et expérience\n",
    "\n",
    "Pour les graphiques on utilise le rapport des spectres simulé et expérimental. La classe `Dataset` fournit les outils pour faire ce type de calculs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array_equal(t4ds.bins['t'], exp_data.bins['t']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Malgré le fait que les bins nous apparaissaient complètement équivalents, ils ne l'étaient pas : cela vient probablement de la conversion de strings (depuis les fichiers ASCII) en float alors que les nombres n'étaient pas écrits de la même manière (`int` pour les données expérimentales, `float` en notation exponentielle à 6 chiffres après la virgule pour Tripoli-4 ayant subis quelques calculs en plus)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = t4ds / exp_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaisons numériques\n",
    "\n",
    "Il est possible de comparer les deux `Dataset` numériquement grâce aux fonctions disponibles dans `gavroche.test.py` qui agissent sur les datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from valjean.gavroche.test import TestApproxEqual\n",
    "test_equality = TestApproxEqual(t4ds, exp_data, name='light criteria on approx eq', rtol=0.1, atol=1e-2)\n",
    "print(bool(test_equality.evaluate()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lors de la VV ce test est davantage fait sur l'intégrale du spectre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integ = sphere_b.select_by(score_name='neutron_response_integral_30deg')\n",
    "intnumds = integ['results']['score'].squeeze()\n",
    "intnumds.name='integ'\n",
    "integds = intnumds / norm / TIME_BIN_WIDTH\n",
    "integds = integds[1:-1]\n",
    "print(integds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Petite vérification de routine rapide :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(np.sum(t4ds.value), integds.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On supprime les bins ici pour simplifier la comparaison (il s'agit d'une intégrale)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "integds.bins = OrderedDict()\n",
    "print(integds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intégrale des données, en supposant les intervalles indépendants :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from valjean.eponine.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quad_err = np.sqrt(np.sum(exp_data.error ** 2))\n",
    "integ_data = Dataset(np.sum(exp_data.value), quad_err)\n",
    "print(integ_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equ_integ = TestApproxEqual(integds, integ_data, name='approx eq integrales', rtol=0.03, atol=1e-4)\n",
    "print(bool(equ_integ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphiques par défaut dans valjean\n",
    "\n",
    "La majorité des tests peut être représentée sous forme de graphique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from valjean.javert.representation import FullRepresenter\n",
    "from valjean.javert.rst import RstFormatter\n",
    "from valjean.javert.mpl import MplPlot\n",
    "from valjean.javert.verbosity import Verbosity\n",
    "\n",
    "frepr = FullRepresenter()\n",
    "rstformat = RstFormatter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teq_res = test_equality.evaluate()\n",
    "eqrepr = frepr(teq_res, verbosity=Verbosity.FULL_DETAILS)  # il s'agit d'une liste de templates\n",
    "eqrst = rstformat.template(eqrepr[1])\n",
    "print(eqrst)\n",
    "mpl = MplPlot(eqrepr[0]).draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec un test de Holm-Bonferroni puisqu'il s'agit d'un spectre :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from valjean.gavroche.stat_tests.student import TestStudent\n",
    "from valjean.gavroche.stat_tests.bonferroni import TestHolmBonferroni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sphere_b.globals\n",
    "studt = TestStudent(t4ds, exp_data, name='Student test', ndf=sphere_b.globals['edition_batch_number'])\n",
    "hb_res = TestHolmBonferroni(test=studt, name='Holm-Bonferroni test', description='').evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hbrepr = frepr(hb_res, verbosity=Verbosity.INTERMEDIATE)  # il s'agit d'une liste de templates\n",
    "hbrst = rstformat.template(hbrepr[1])\n",
    "print(hbrst)\n",
    "mpl = MplPlot(hbrepr[0]).draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'autres niveaux de verbosité sont disponibles. Il est également possible de changer un peu la représentation graphique des tests en utilisant une échelle logarithmique pour les données et la simulation par exemple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from valjean.javert import plot_repr as pltr\n",
    "def log_post(templates, tres):\n",
    "    pltr.post_treatment(templates, tres)\n",
    "    for templ in templates:\n",
    "        templ.subplots[0].attributes.logy = True\n",
    "    return templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbrepr = FullRepresenter(post=log_post)(hb_res, verbosity=Verbosity.FULL_DETAILS)  # il s'agit d'une liste de templates\n",
    "print(len(hbrepr[1:]))\n",
    "hbrst = '\\n'.join([str(rstformat.template(hbrepr[1])), str(rstformat.template(hbrepr[2]))])\n",
    "print(hbrst)\n",
    "mpl = MplPlot(hbrepr[0]).draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'impression des résultats des `TestStudent` dans le cas `FULL_DETAILS` donne le tableau de Student en `INTERMEDIATE`, soit les bins où le test à échouer.\n",
    "\n",
    "**Remarque** : le test de Holm-Bonferroni n'est pas très adapté ici, comme nous comparons les données à la simulation, nous n'avons pas de nombre de degrés de liberté similaire pour les deux échantillons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphiques de comparaison entre les données expérimentales et Tripoli-4\n",
    "\n",
    "L'analyse des données peut également être faite en dehors de **valjean** en fonction de ses nécessités.\n",
    "\n",
    "Comme pour la lecture des résultats expérimentaux, une petite classe a été dérivée pour facilier et personnaliser les graphiques de comparaison.\n",
    "\n",
    "La bibliothèque utilisée est `matplotlib`.\n",
    "\n",
    "Dans notre cas, on souhaite aisément :\n",
    "\n",
    "- ajouter une nouvelle courbe, avec ses erreurs\n",
    "- visualiser le rapport entre les différentes courbes\n",
    "- pouvoir personnaliser facilement la couleur et l'aspect des courbes (aisé grâce à `matplotlib`, les arguments sont juste transmis ici)\n",
    "\n",
    "Cette petite classe, [CompPlot](comp_plots.py), est aussi disponible dans le notebook.\n",
    "\n",
    "Le nom de « l'analyse » correspond à la clef pour les données expérimentales. Cela permet de générer par exemple le titre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from comp_plots import CompPlot\n",
    "\n",
    "cplot = CompPlot(exp_key)\n",
    "cplot.add_errorbar_plot(exp_data.bins['t'], exp_data.value, exp_data.error,\n",
    "                        fmt='o', c='black', ms=2, ecolor='black', label='Experiment')\n",
    "cplot.add_errorbar_plot(t4ds.bins['t'], t4ds.value, t4ds.error,\n",
    "                        label='T4', drawstyle='steps-mid', fmt='-', c='orange')\n",
    "\n",
    "cplot.add_errorbar_ratio(ratio.bins['t'], ratio.value, 0,\n",
    "                         drawstyle='steps-mid', fmt='-', c='green')\n",
    "cplot.splt[1].fill_between(\n",
    "    ratio.bins['t'],\n",
    "    np.ones(ratio.bins['t'].size) - exp_data.error/exp_data.value,\n",
    "    np.ones(ratio.bins['t'].size) + exp_data.error/exp_data.value,\n",
    "    facecolor='lightgrey', step='mid')\n",
    "cplot.customize_plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
